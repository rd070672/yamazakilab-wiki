# 物理インフォマティクスにおける PINNs とその発展形  

## 参考にしたドキュメント
- MathWorks, Physics-Informed Neural Networks (PINNs) とは  
  https://jp.mathworks.com/discovery/physics-informed-neural-networks.html
- PINN入門: 物理法則を組み込んだAIで微分方程式を解く  
  https://www.codemajin.net/introduction-to-physics-informed-neural-network/
- PINN 解説（日本語, 物理情報学会）  
  https://www.msiism.jp/article/physics-informed-machine-learning2.html 


## 1. 位置づけ：PINNs は「物理インフォマティクスのエンジン」

- Physics-Informed Neural Networks（PINNs）は、
  - 「微分方程式（PDE）という形で与えられた物理法則」を
  - ニューラルネットワークの損失関数として組み込むことで、
  - データと物理モデルを同時に満たす関数を学習する枠組みである。
- 物理インフォマティクスの文脈では、PINNs は
  - DFT・MD・FEM などの既存シミュレーションに代わる／補完する「物理一体型サロゲート」
  - 実験データと物理モデルを結び付ける「逆問題ソルバ」
  として機能する「エンジン」の一つとみなせる。

ここでは、標準的な PINNs を前提として、その発展形（XPINNs, VPINNs, hp-VPINNs, PINO など）を  
「物理インフォマティクスでどう活かすか」という観点で整理する。


## 2. 基本的な PINNs のアイデア

- ニューラルネットワーク #u_\theta(x,t)# で未知の解関数を近似し、
- 損失関数に
  - PDE 残差（微分方程式を満たすか）
  - 初期条件・境界条件
  - 必要に応じて観測データとの誤差
  を同時に含めて最適化する。
- メッシュフリーであること、異なる PDE に比較的簡単に適用できることが利点だが、
  - マルチスケール問題や高次元問題、長時間積分では収束が難しい
  - 損失項のスケール調整がシビア
  などの課題があり、それを解決する形で多数の「発展版」が提案されている。


## 3. 発展形の系統図

物理インフォマティクスの観点からは、発展版 PINNs を次の 4 つに分けて整理すると分かりやすい。

1. ドメイン分割型：  
   - cPINNs（Conservative PINNs）、XPINNs（eXtended PINNs）など  
   → 大規模／複雑ジオメトリ／並列計算向け。

2. 変分・弱形式型：  
   - VPINNs（Variational PINNs）、hp-VPINNs など  
   → 有限要素法（FEM）的な視点で安定性・精度を高める。

3. Neural Operator 型：  
   - FNO（Fourier Neural Operator）に PDE 制約を加えた PINO（Physics-Informed Neural Operator）など  
   → 「方程式の解」ではなく「解作用素そのもの」を学ぶ。

4. 損失設計・マルチフィデリティ型：  
   - 損失重み自動調整、エネルギー汎関数ベース、  
     低忠実度＋高忠実度を組み合わせる Multi-Fidelity PINNs など。

以下、それぞれを「物理インフォマティクスでどう使えるか」に絡めて簡潔にまとめる。


## 4. ドメイン分割型：cPINNs / XPINNs

### 4.1 cPINNs（Conservative PINNs）

- 特徴
  - 計算領域をサブドメインに分割し、各サブドメインに別々の PINN を割り当てる。
  - サブドメイン境界で「フラックスの連続」など、保存則に対応する条件を課すことで、
    保守的な解を得る。
- 物理インフォマティクスでの使いどころ
  - マクスウェル方程式、連続の式、運動量保存など、
    保存則が重要な PDE を扱うときに、
    物理的に意味のある解を保ちやすい。
  - 例えば「渦電流＋磁場＋熱」の連成解析で、
    領域を電磁・熱で分けて学習するといった応用を考えやすい。

### 4.2 XPINNs（Extended PINNs）

- 特徴
  - 空間だけでなく「空間×時間ドメイン」を柔軟に分割できる一般化フレームワーク。
  - サブドメインごとに異なるネットワーク・時間刻みを使えるため、
    並列計算や局所的高分解能に向く。
- 物理インフォマティクスでの使いどころ
  - マイクロ磁気 LL(G) など「長時間・広い空間」を扱うときに、
    - 短時間・高時間分解能が必要な領域
    - 長時間・粗い分解能でよい領域  
    を分けて学習する、といった工夫が可能。
  - 複雑形状・多領域（磁性体／空気／コイルなど）を扱う FEM 的シナリオとも相性が良い。


## 5. 変分・弱形式型：VPINNs / hp-VPINNs

### 5.1 VPINNs（Variational PINNs）

- 特徴
  - PDE の「点ごとの残差」ではなく「変分形式（弱形式）」を損失にする。
  - テスト関数との積分で残差を評価するため、
    強形式 PINNs よりもノイズに強く、数値安定性がよい場合がある。
- 物理インフォマティクスでの使いどころ
  - 元々 FEM を使っていたような問題（弾性体・熱伝導・拡散・LLG など）との親和性が高く、
    「従来コードで使っていた弱形式を、そのまま PINNs に移植」しやすい。
  - 実験データが粗い場合にも、「積分量」を合わせにいく発想と相性がよい。

### 5.2 hp-VPINNs

- 特徴
  - VPINNs に「hp 有限要素法」の考え方を持ち込み、
    - 領域分割（h-refinement）
    - 高次多項式によるテスト空間拡張（p-refinement）
    を組み合わせることで、局所的に難しい領域に解像度を集中させる。
- 物理インフォマティクスでの使いどころ
  - 磁壁・亀裂先端・界面・境界層など、
    物理的に「局所的に難しい部分」がはっきりしている問題に向く。
  - 既存の FEM コードのテスト関数空間と整合させながら、
    NN を「試行関数空間」として導入するブリッジとして利用できる。


## 6. Neural Operator 型：FNO と PINO

### 6.1 Neural Operator / FNO（Fourier Neural Operator）

- アイデア
  - 「特定の格子上の解」を学ぶのではなく、
    「境界条件・係数場 → 解関数」という写像（解作用素）を丸ごと近似する。
- FNO
  - スペクトル空間（Fourier 領域）での畳み込みを用いた Neural Operator。
  - 離散化に依存しにくく、異なる格子でも同じ演算子を使い回せる。

### 6.2 PINO（Physics-Informed Neural Operator）

- 特徴
  - FNO に「PDE 残差」を加えたものが PINO。
  - 粗い格子上のデータで教師あり学習しつつ、
    より細かい格子上で PDE 制約を課すハイブリッド学習が可能。
  - ゼロショット・スーパーリゾリューション（学習時より細かい格子での予測）に強い。

- 物理インフォマティクスでの使いどころ
  - 「プロセス条件や材料パラメータが毎回変わる」シナリオで、
    一度学習した演算子を使って高速に PDE 解を生成するサロゲートとして使える。
  - 例えば「磁気材料のパラメータ分布 → 磁区構造」「微細構造 → 渦電流分布」のような  
    マッピングを、一括でオペレータとして学習するイメージ。


## 7. 損失設計・マルチフィデリティなどの高度化

物理インフォマティクスの現場では、「どう損失を書き、どう学習させるか」が実務上の肝になる。

代表的な工夫：

- 損失項の自動重み付け
  - PDE 残差・境界条件・データ項のスケール差を、勾配ノルムなどに基づいて動的に補正。
- エネルギー汎関数ベースの PINNs
  - PDE ではなく対応するエネルギー汎関数や作用積分を最小化する形にし、
    安定性と物理整合性を高める。
- マルチフィデリティ PINNs
  - 粗いシミュレーション（FEM/MD の低忠実度）と、
    一部の高忠実度計算や実験データを統合して学習することで、
    トータルのコストと精度を両立させる。


## 8. 物理インフォマティクス全体の中での「使い分け」

物理インフォマティクスのワークフローに組み込むときの雑な指針：

- 小規模・比較的単純な PDE（1D/2D のテスト問題など）
  - → 標準 PINNs ＋ 損失設計の工夫から始める。

- 複雑形状・長時間積分・多領域連成
  - → XPINNs / cPINNs / hp-VPINNs で  
    FEM 的なドメイン分割・弱形式の考え方を導入する。

- 多数の条件・パラメータを一度に扱いたい / 高速サロゲートが欲しい
  - → Neural Operator / PINO を用いて  
    「方程式の解作用素」を一括して学習する。

- DFT・MD・FEM・実験データをまとめて扱いたい
  - → 高忠実度シミュレーションで生成したデータと、実験データを  
    マルチフィデリティ PINNs / PINO に統合し、  
    物理的制約を保ったまま高速な surrogate を構築する。
