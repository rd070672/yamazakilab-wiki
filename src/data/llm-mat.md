# 材料科学分野における LLM（Large Language Model）

LLM（大規模言語モデル）は、自然言語（論文・ノート・仕様書・プロトコル）を入口として、材料データベースや計算・計測ツールに接続し、検索・要約・抽出・提案を一体化するための基盤技術である。材料インフォマティクスでは「非構造データ（文章）」を「設計・実験・計算の意思決定」に変換する役割を担う。

![alt text](image.png)

## 参考ドキュメント
- 東京科学大学（Science Tokyo）プレスリリース：大規模言語モデルによるひらめきの創出（SELLM）  
  https://www.isct.ac.jp/ja/news/wkceh2wvoa0u
- miLab（MI-6）記事：LLMの材料開発における活用事例 Part1  
  https://milab.mi-6.co.jp/article/t0034
- NIMS（SAMURAI / MDR）：MaterialBERT for natural language processing of materials science texts  
  https://samurai.nims.go.jp/articles/8e14c678-cceb-4b9e-8a3e-66f247d04266?locale=en


## 1. 位置づけ（材料MIの中でLLMが得意なこと）
- 文献・特許・実験ログなど、文章中心の知識を扱う（情報抽出、要約、比較、レビュー作成）
- 材料DB・計算コード・計測装置の「操作インターフェース」になり得る（Tool/Agent化）
- アイデア生成（仮説、代替材料、原因候補の列挙）を支援する（ただし検証必須）

一方で、数値の厳密性や物理拘束の保証は自動ではないため、RAGや外部計算・外部DB照会を併用して“事実に寄せる設計”が重要である。

## 2. 基本原理（最小限）
LLMは「次トークン予測」を学習したモデルであり、典型的には以下を最大化する：

$$
\max_{\theta}\sum_{t}\log p_{\theta}(w_t \mid w_{<t})
$$

実運用では、これに「検索（retrieval）」と「道具（tools）」を付けることで、材料科学に必要な再現性と事実性を補う。

## 3. 材料科学での代表的ユースケース
### 3.1 文献・特許・社内資料のテキストマイニング
- 材料名、組成、プロセス条件、物性値、測定手法の抽出（NER）
- “Aが増えるとBが変わる”のような関係抽出（Relation Extraction）
- トレンド分析（頻出材料、条件レンジ、未探索領域）

ポイント：一般LLMより、材料コーパスで事前学習された言語モデル（例：MaterialBERT/MatSciBERT系）を使うと抽出が安定しやすい。

### 3.2 Q&A（ラボ内知識ベース、装置マニュアル、計算手順）
- ラボwikiの質問応答（例：「この測定の最短手順は？」）
- SOPの自動整形、チェックリスト生成
- 解析レポートの草案化

ポイント：回答には参照元（ページ、論文、ログ）の提示を必須にする運用が望ましい。

### 3.3 材料DBや計算・解析ツールの“自然言語UI”化（Tool/Agent）
例：Materials Project等のDBを呼び出し、格子定数や構造を取得して次の操作に渡す、など。
- 入力：自然言語（「WSe2の(012)ピークに合わせたい」）
- 途中：DB照会→パラメータ計算→装置/コードへコマンド生成
- 出力：実行可能な設定値、ログ、再現可能な手順

### 3.4 研究アイデア生成・課題解決の“列挙器”
- 制約（温度上限、元素制限、プロセス制約）を与え、候補案を網羅的に列挙
- 既存知識リスト（元素、構造、プロセス、特許分類など）を“探索空間”として与えると、発想の偏りを減らしやすい

注意：創造的提案は強いが、成立性は別問題である。提案は必ず「検証パイプライン（計算・実験・既存DB照会）」へ流す設計にする。

## 4. 実装の定石：RAG（Retrieval-Augmented Generation）
### 4.1 何を解決するか
LLM単体は、学習データにない事実をそれらしく補完してしまう（ハルシネーション）ため、
材料DB・論文PDF・ラボノート等から“根拠文書”を検索し、その範囲で回答させる。

### 4.2 最小構成
- 文書集合 $\mathcal{D}$（論文、マニュアル、wiki、測定ログ）
- 埋め込みベクトル $e(x)$（クエリと文書を同一空間へ）
- Top-k検索：$\mathcal{D}_k = \operatorname{TopK}_{d\in\mathcal{D}} \ \mathrm{sim}(e(q), e(d))$
- LLM入力：質問 + 取得文書（引用必須）+ 出力フォーマット

RAGの見取り図（概念）：
- User Query → Retriever（Top-k）→ Context → LLM → Answer（citations）

## 5. 実装の定石：Tool/Agent（外部関数呼び出し）
RAGに加えて、LLMが外部ツールを呼べるようにすると、材料科学タスクが一段実務寄りになる。
- ツール例：Materials Project API、pymatgen、XRDピーク計算、DFTワークフロー、実験装置制御I/F
- 重要：ツール入出力をJSON等の構造化形式に固定し、ログを保存する（再現性）

## 6. モデル選択の考え方
1) 文献抽出が目的：材料コーパスで事前学習されたモデル（BERT系）＋タスク別fine-tuning  
2) 対話・要約・研究支援が目的：汎用LLM + RAG（ラボ内文書）  
3) DB照会や計算連携までやりたい：汎用LLM + Tool/Agent + RAG（事実性の担保）

## 7. 評価
材料向けLLMは、一般ベンチマークだけでは評価できない。
- 材料知識Q&A（学部〜院レベルの概念問題）
- 物性値・単位・条件の数値整合性（“結論”より“整合性”）
- 参照根拠の妥当性（引用が実際に答えを支えているか）
- 再現性（同じ入力でブレないか、ログが残るか）

簡易チェック項目：
- 数値は出典付きか
- 単位換算を明示したか
- “推測”と“事実”を分離したか
- 外部DB照会が可能な項目は照会したか

## 8. 注意点
- 物性値・単位・規格条件（温度、圧力、結晶相、測定法）が混線しやすい
- “ありそうな相図”や“それっぽい機構”を生成しがちである（図・機構は要注意）
- ライセンス（論文PDF、データベース、社内資料）と機密の扱いを統一する必要がある
- 実験操作に接続する場合は、安全設計（権限、二重承認、フェイルセーフ）を最初から入れるべきである

## 9. まとめ
材料科学におけるLLMは、文章知識の抽出・統合と、DB/計算/計測への接続を通じて、研究の探索と実務を加速する基盤である。実用上は、RAGで根拠を固定し、Tool/Agentで事実を外部から取得し、評価指標（数値整合性・出典妥当性・再現性）を明確にした運用設計が要点である。
