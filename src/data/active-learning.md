# アクティブラーニングと能動学習

アクティブラーニング（AL）とは、学習に有効なデータ点（次に測るべき条件）をモデル自身が提案し、限られた実験・計算回数でモデル性能や知識獲得を最大化する枠組みである。材料研究では「ラベル付け（DFT/実験）が高コスト」な状況で、データ取得を賢く配分するための基盤技術である。

## 参考ドキュメント
- Burr Settles, Active Learning Literature Survey (2009)（PDF）
  https://burrsettles.com/pub/settles.activelearning.pdf
- 長岡正宏, 能動学習による実験条件の効率的探索（成形加工, 2024, J-STAGE PDF）
  https://www.jstage.jst.go.jp/article/seikeikakou/36/10/36_436/_pdf/-char/ja
- Kusne et al., On-the-fly closed-loop materials discovery via Bayesian active learning (Nature Communications, 2020)
  https://www.nature.com/articles/s41467-020-19597-w


## 1. ALの目的と、ベイズ最適化（BO）との違い
ALの主目的は、モデルを良くするために“どのデータを追加取得すると効率が良いか”を決めることである。
- AL：モデル精度向上、未知領域の不確かさ低減、設計空間の理解（学習効率が主）
- BO：目的関数の最大/最小（最良点の発見が主）

実務では、ALで予測モデルを育てつつ、BOで最適条件へ寄せる、あるいは両者を同じ獲得関数で統合して運用することが多い。

## 2. 問題設定
- 設計変数：$\mathbf{x} \in \mathcal{X}$（組成、温度、時間、プロセス条件など）
- 未ラベル候補集合：$U=\{\mathbf{x}_j\}$（まだ測っていない条件群）
- 既知データ（ラベル付き）：$L=\{(\mathbf{x}_i, y_i)\}$（測定/計算済み）
- オラクル：$y = f(\mathbf{x}) + \varepsilon$ を返す装置・計算（実験、DFT、MDなど）
- 予算：取得回数 $B$、並列数 $q$、1点コスト、時間制約など

ALは次のループで動く：
1) 初期データ $L$ を用意（DOE等で広く撒く）
2) 予測モデル $p(y|\mathbf{x},L)$ を学習
3) スコア（獲得関数）$a(\mathbf{x})$ が大きい候補を選ぶ
4) オラクルでラベル取得し $L \leftarrow L \cup \{(\mathbf{x},y)\}$
5) 予算が尽きるまで繰り返す

## 3. 何を基準とするか
ALの肝は「スコア $a(\mathbf{x})$ の設計」である。材料科学では回帰（連続値物性）が多いが、分類（相の有無、合成成功/失敗）も頻出である。

### 3.1 不確実性サンプリング（Uncertainty Sampling）
よく分からない所を優先して測る。

分類（クラス $c$）の例：予測確率 $p(c|\mathbf{x})$ のエントロピー
$$
a(\mathbf{x}) = H[y|\mathbf{x}] = -\sum_c p(c|\mathbf{x})\log p(c|\mathbf{x})
$$

回帰の例：予測分散（予測不確かさ）
$$
a(\mathbf{x}) = \mathrm{Var}[y|\mathbf{x}]
$$

### 3.2 委員会学習（Query by Committee; QBC）
複数モデル（またはアンサンブル）が“揉める”点を優先する。
回帰の例（アンサンブル予測 $\hat{y}^{(m)}$）：
$$
a(\mathbf{x}) = \mathrm{Var}_{m=1..M}\left[\hat{y}^{(m)}(\mathbf{x})\right]
$$
材料予測やMLポテンシャルでは、アンサンブル差分を“不確かさ”として使う設計が実装しやすい。

### 3.3 情報量最大化（Information Gain / BALD）
「パラメータ不確かさを最も減らす点」を選ぶ考え方である（ベイズ的）。
$$
a(\mathbf{x}) = I(y,\theta|\mathbf{x},L)
= H[y|\mathbf{x},L] - \mathbb{E}_{p(\theta|L)}[H(y|\mathbf{x},\theta)]
$$
モデルが“何を学べばよいか”をより原理的に定義できるが、近似計算が必要になることが多い。

### 3.4 多様性・代表性（Diversity / Core-set）
不確実性だけで選ぶと、似た点ばかり選んでしまうことがある。そこで「未カバー領域」を優先する。
特徴空間 $\phi(\mathbf{x})$ を用いて：
$$
a(\mathbf{x}) = \min_{\mathbf{x}_i\in L}\|\phi(\mathbf{x})-\phi(\mathbf{x}_i)\|
$$
バッチ取得（並列実験）と相性が良い。

### 3.5 目的指向AL（Targeted AL）
全体精度ではなく、ある領域（例：高性能域、相境界付近、合成可能域）を重点的に学ぶ設計である。
- 相境界推定（level-set）：相が変わる境界近傍を優先
- 仕様到達：目標値 $y \ge y^*$ を満たす確率を上げる 等

## 4. 典型ユースケース
### 4.1 物性予測モデルのデータ取得最適化
候補（組成・プロセス）を大量に想定できる一方、ラベル（実験・DFT）が高コストで少数しか取れない場面でALが効く。
- 例：合金組成空間で、強度や磁気特性を効率よく学習
- 例：焼結条件（温度–時間–圧力–添加剤）から密度・特性を学習

### 4.2 機械学習ポテンシャル（MLIP）の能動学習
MDで探索（探索）、DFTでラベル付け（ラベリング）、再学習（学習）を自動反復する枠組みが確立している。
- 例：DP-GEN（explore–label–train のループ）
- 例：FLARE（モデル不確かさで追加DFTの要否を判断しオンザフライ学習）

### 4.3 自律実験・閉ループ材料探索（Closed-loop）
ロボット合成・自動測定・解析・次条件提案を統合し、AL/BOで探索を回すアプローチである。
材料探索の「実験の並び替え」をアルゴリズム化できる点が強い。

## 5. ワークフロー
1) 目的定義：精度向上（全体）か、相境界/高性能域重視か
2) 初期データ：DOE（空間充填、中心点、混合計画など）で少数点を確保
3) サロゲート選定：
   - 少数データ：GP回帰、ランダムフォレスト、アンサンブルNN など
   - 不確かさ推定が要件（分散、アンサンブル差、ベイズ近似）
4) スコア設計：
   - まずは不確実性 + 多様性の混合が安定
5) 制約処理：
   - 合成不可能域、装置上限、危険域はハード制約として除外
6) バッチ運用：
   - 1日 q点の並列取得に合わせてバッチAL（多様性を必ず入れる）
7) 停止条件：
   - 予算枯渇、学習曲線の頭打ち、目標性能到達、追加実験価値の低下 など

## 6. 注意点
- ノイズ・再現性：同一条件の反復を混ぜ、観測ノイズとしてモデル化する
- 相変化の急峻さ：局所的に不連続が出るため、初期DOEを厚めにし、境界付近へ重点化する
- 外挿の暴走：不確かさ推定が弱いモデルだと危険。アンサンブルや検証用ホールドアウトを用意する
- 似た点ばかり取る：不確実性のみは危険。多様性（core-set等）を必ず混ぜる
- “最適化”と混同：ALは学習効率、BOは最良点の探索。目的に応じて獲得関数を切り替える

## まとめ
アクティブラーニングは、モデルが「次に測るべき条件」を提案してデータ取得を最適配分し、少ない実験・計算回数で学習効率と発見効率を高める枠組みである。材料研究では、物性予測のデータ収集、MLポテンシャルのデータ生成、閉ループ自律実験において特に有効であり、DOEと併用して運用するのが実務的である。
