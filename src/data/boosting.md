# 勾配ブースティング決定木（Gradient Boosting, GBDT）

勾配ブースティングは、弱学習器（多くは浅い決定木）を逐次追加し、損失関数を最小化する方向に予測関数を改善していくアンサンブル学習である。材料科学では、組成・構造記述子・プロセス条件などの表形式特徴量に対して高精度なベースラインになりやすく、少量データでも強い選択肢である。

## 参考ドキュメント
- Friedman, J.H., Greedy function approximation: A gradient boosting machine, Annals of Statistics (2001)
  https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full
- Chen, T. and Guestrin, C., XGBoost: A Scalable Tree Boosting System (2016)
  https://arxiv.org/abs/1603.02754
- Qiita: 勾配ブースティング決定木ってなんぞや（日本語）
  https://qiita.com/kuroitu/items/57425380546f7b9ed91c


## 1. 決定木アンサンブルの中での役割
決定木アンサンブルは大別して、バギング系とブースティング系に分かれる。
- バギング（例：ランダムフォレスト）は、学習器を並列に作って平均化し、主に分散を下げる枠組みである
- ブースティング（勾配ブースティング）は、学習器を逐次追加して誤差を補正し、精度を上げる枠組みである

材料データは非線形性・相互作用が強く、外れ値や欠損も混じりやすい。勾配ブースティングは、表形式データに対して高い汎用性と精度を両立しやすい。

## 2. 関数空間での最適化
学習データを $(x_i, y_i)$、予測関数を $F(x)$、損失関数を $L(y, F(x))$ とする。

ブースティングは加法モデルとして
$$
F_M(x)=\sum_{m=0}^{M} \nu\, f_m(x)
$$
の形で予測関数を構成する。ここで $f_m$ は弱学習器（決定木）、$\nu$ は学習率（shrinkage）である。

勾配ブースティングでは、各反復 $m$ で擬似残差
$$
r_{im} = -\left.\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right|_{F=F_{m-1}}
$$
を計算し、$r_{im}$ を目的変数として決定木 $f_m$ を当てはめる。次に
$$
F_m(x)=F_{m-1}(x)+\nu\, f_m(x)
$$
で更新する。これにより損失が下がる方向へ段階的に改善される。

回帰（例：二乗誤差）では、擬似残差は通常の残差に一致する。
$$
L = \frac{1}{2}(y-F)^2 \Rightarrow r = y - F
$$

分類ではロジスティック損失などを用い、確率推定として解釈できる。

## 3. GBDTで重要なハイパーパラメータ
勾配ブースティングは高精度になりやすい一方、過学習制御は設計の要である。

| 役割 | 代表パラメータ | 直観（材料データでの意味づけ） |
|---|---|---|
| モデル容量 | 木の深さ、葉数 | 相互作用の複雑さをどこまで許すかである |
| 学習の刻み | 学習率 $\nu$、木の本数 | 小さく刻むほど安定するが計算が増える |
| ランダム性 | 行サブサンプル、列サブサンプル | ノイズやリーク耐性を上げる方向に働く |
| 正則化 | L1/L2、葉の最小データ数 | 文献混在・条件混在の過学習を抑える |
| 欠損への対応 | 欠損分岐の扱い | 実験条件欠損や記録漏れがある場合に効く |

材料では、ランダム分割の過大評価（近縁組成や同系列の混入）を避け、グループ分割や外挿評価を先に固定したうえでチューニングするのが実務的である。

## 4. 代表的手法
勾配ブースティング自体は概念であり、実装により速度・欠損・カテゴリ処理・正則化の作法が異なる。

### 4.1 XGBoost
- 目的関数の正則化を明示し、大規模・疎な特徴量でも高速化する工夫が多い
- 二階微分（ヘッセ行列）まで使う近似で、分割評価を効率化する設計である

材料では、Magpie系の組成特徴や構造統計量など、疎になりがちな特徴を扱う場面で使いやすいことが多い。

### 4.2 LightGBM
- ヒストグラム（ビン）ベースで分割点探索を高速化する
- 葉優先（leaf-wise）成長を採るため、深くなりやすく、過学習制御（葉数制約など）が重要である
- 大規模特徴量に対して効率化手法（GOSS/EFBなど）を導入している

多変量プロセスログや高次元記述子を扱う場合に計算面の利点が出やすい。

### 4.3 CatBoost
- カテゴリ特徴の処理を重視し、ターゲットリーク由来のバイアスを抑える工夫（ordered boostingなど）を特徴とする

材料では、合成法カテゴリ、装置ID、研究グループ、測定モードなどのカテゴリ情報を条件として入れたい場合に選択肢になる。

## 5. 典型タスク
### 5.1 物性予測（回帰）
- 形成エネルギー、バンドギャップ、弾性定数、熱伝導率、磁気特性指標など
- 入力は、組成統計・構造記述子・プロセス条件の表形式が中心である

### 5.2 相・状態の分類
- 相分類、合成成功/失敗、二次相混入の有無、異常検知など
- XRDや各種スペクトルは、ピーク特徴量（位置・強度・幅）に落として表形式化するとGBDTで強いことがある

### 5.3 逆設計・探索への接続
- 学習した順モデル（条件→性能）を用い、ベイズ最適化や制約付き探索に接続して候補条件を提案する
- 材料では、モデル精度よりも「安全に探索できる評価設計」と「制約の持ち方」が支配的である

## 6. 注意点
- データリーク対策が必須である（近縁組成・同系列・同研究条件の混入）
- 外挿評価（未知組成域、未知元素系、未知プロセス域）を明示すべきである
- 重要度・寄与の解釈に注意が必要である（分割利得ベースは偏りうるため、Permutation importanceやSHAPの併用が現実的である）

## まとめ
勾配ブースティングは、損失関数の勾配に基づいて弱学習器（決定木）を逐次追加し、表形式データで高精度を出しやすい教師あり学習である。材料科学では、組成・構造記述子・プロセス条件のような非線形かつ相互作用の強い特徴に対して有効である一方、近縁材料混入によるリーク対策と外挿評価設計が成否を決める。
