# 線形次元削減（Linear Dimensionality Reduction）

高次元の材料データを、線形写像により低次元へ圧縮し、可視化・ノイズ低減・特徴抽出・学習安定化を行う枠組みである。材料科学では、スペクトル・回折・計測時系列・計算記述子などの「多変量データ」を、物理解釈しやすい潜在変数（latent variables）に整理する操作として重要である。

## 参考ドキュメント
- Pearson, K. On lines and planes of closest fit to systems of points in space (1901)
  http://pbil.univ-lyon1.fr/R/pearson1901.pdf
- Torgerson, W. S. Multidimensional scaling: I. Theory and method (1952)
  https://www.galileoco.com/literature/torgerson52.pdf
- 京都大学 データ分析基礎：主成分分析＋演習の手順（講義スライド, 日本語）
  https://ds.k.kyoto-u.ac.jp/wp-content/uploads/2021/10/slide-05.pdf


## 1. 次元削減が必要となる場面
1) スペクトル・回折の高分解能化
XAFS/XPS/XRD/Raman などは、1試料あたりエネルギー（角度）点が数百〜数万になり、変数数 p が巨大になりやすい。

2) ハイスループット（組成スプレッド、プロセス探索）
試料数 n が増え、条件（温度、雰囲気、膜厚、アニール条件など）も増えると、相関・クラスタ・外れ値の把握が難しくなる。

3) 記述子の多重共線性
元素特徴量、SOAP/ACSF、DOS特徴、プロセス特徴などは相互に強く相関しやすく、回帰が不安定になりやすい。

4) 可視化が目的の探索解析
2次元や3次元への投影を通じて、相境界、混相、異常測定、ドリフトを直感的に把握したい。

## 2. 代表的な線形手法（一覧）
| 手法 | 入力 | 出力（低次元表現） | 目的関数（代表） | 材料科学での使いどころ |
|---|---|---|---|---|
| PCA（主成分分析）/ SVD | データ行列 X（n×p） | スコア T（n×r）, 負荷 W（p×r） | 分散最大化 / 再構成誤差最小化 | スペクトル・回折の圧縮、ノイズ低減、探索可視化、特徴抽出 |
| Classical MDS（古典MDS）/ PCoA | 距離行列 D（n×n） | 座標 Z（n×r） | 距離の内積表現への射影 | 類似度に基づく地図化（指紋距離、スペクトル距離） |
| LDA（線形判別分析） | X とラベル y | 判別軸 z（n×r） | クラス間分散 / クラス内分散 最大化 | 相分類、合成成否、欠陥有無など「ラベルあり」可視化 |
| PLS（部分最小二乗） | X と目的 y（回帰/分類） | 潜在変数 t（n×r） | X と y の共分散最大化 | 機器分析（スペクトル）での定量、プロセス→物性回帰の安定化 |
| CCA（正準相関分析） | 2つの観測 X, Y | (u, v) の対（正準変数） | corr(u, v) 最大化 | マルチモーダル連携（XAFS↔XRD、実験↔計算、画像↔物性） |
| NMF（非負値行列因子分解） | 非負行列 X≥0 | W≥0, H≥0 | 非負制約下での再構成誤差最小化 | 混合スペクトル/混相パターンの分解（部分スペクトル・相寄与） |

以降、材料データで遭遇頻度が高い順に、要点と設計の勘所を述べる。

## 3. PCA / SVD：最も基本の線形圧縮
### 3.1 定義（中心化したデータの線形射影）
試料 n、変数 p のデータ行列を $X∈R^{n×p}$ とし、列平均を引いた中心化行列を $X_c$ とする。PCA は
- 低次元表現（スコア）  $T = X_c W$
- 近似再構成  $X_c ≈ T W^T$
を満たす負荷行列 W（直交基底）を求める。

共分散 $S = (1/(n-1)) X_c^T X_c$ の固有値分解
$$
S w_k = \lambda_k w_k,\quad \lambda_1 \ge \lambda_2 \ge \cdots
$$
により、上位 r 成分を採用する。

SVD との関係は
$$
X_c = U \Sigma V^T,\quad W = V_{(:,1:r)},\quad T = U_{(:,1:r)}\Sigma_{1:r}
$$
であり、数値的には SVD 実装で扱うことが多い。

### 3.2 解釈のコツ
- スコア T：各試料が潜在空間でどこに位置するか（相・組成・プロセス変化の軌跡を描く）
- 負荷 W：どの変数（例えばエネルギー点、2θ点、特徴量）がその軸を作っているか（物理的な寄与の手がかり）

ただし PCA の軸の符号反転は任意であり、符号そのものに物理意味を持たせすぎない設計が必要である。

### 3.3 よくある前処理（スペクトル・回折）
- ベースライン補正、正規化（面積・最大値・post-edge など）
- 計測条件の揺れ（オフセット、ドリフト）補正
- 必要に応じて微分や平滑化を行うが、物理的意味（ピーク形状、ノイズ増幅）を確認する

## 4. Classical MDS / PCoA：距離に基づく線形埋め込み
PCA が「変数空間の線形部分空間」を作るのに対し、MDS は「試料間距離」を入力として低次元座標を与える方法である。距離行列 D（要素 d_{ij}）から、二重中心化により内積行列 B を構成する：
$$
B = -\frac{1}{2} J D^{\circ 2} J,\quad J = I - \frac{1}{n}\mathbf{1}\mathbf{1}^T
$$
B の固有分解 $B = Q \Lambda Q^T$ により、座標は
$$
Z = Q_{(:,1:r)} \Lambda_{1:r}^{1/2}
$$
で得られる。

材料科学で特に有用なのは、距離の設計自由度が高い点である。
- 指紋ベクトルの距離（cosine, L2）
- スペクトル間の距離（相関距離、Wasserstein/EMD など）
- 構造類似度（結晶指紋・局所環境記述子の距離）

距離が変われば地図も変わるため、何を類似とみなすか（物理仮説）を先に明確化する必要がある。

## 5. LDA：ラベルありの線形可視化・圧縮
PCA が分散最大化なのに対し、LDA はクラス判別を目的とする。2クラスの基本形は
$$
J(w)=\frac{w^T S_B w}{w^T S_W w}
$$
を最大化する w を求め、$z = X w$に射影する。ここで $S_B$ はクラス間散布、$S_W$ はクラス内散布である。

材料での典型例は、相（A/B/混相）、合成成否、異常試料（測定不良）などの分類境界を可視化することである。注意点として、ラベルが測定条件やロットと強く結びつくと、モデルが物性ではなく条件差を学習する危険がある。

## 6. PLS：目的変数を見ながら圧縮する（回帰で頻出）
PCA は y を見ないが、PLS は X と y の関係を保ちながら X を低次元化する。概念的には
- 潜在変数 $t = X w$ を作り
- t と y の共分散（あるいは説明力）が大きくなるように w を選び
- 残差を更新しつつ成分を積み上げる
枠組みである。

材料計測（特に機器分析）では、スペクトル全体から定量値（濃度、組成、官能基量）を推定する chemometrics で頻出であり、説明変数が多く相関が強い状況に強い。

## 7. CCA：マルチモーダル（2視点）を線形に結び付ける
X（例：XAFS）と Y（例：XRD, 物性, 画像特徴）に対し
$$
u = a^T X,\quad v = b^T Y,\quad \max_{a,b}\ \mathrm{corr}(u,v)
$$
を満たす (u, v) の系列を求めるのが CCA である。材料科学では「同一試料を別の測定で見た」状況が多く、物理的に対応する変動（相変化、局所構造変化、欠陥度）を抽出する導線になりやすい。

高次元では過学習しやすいので、正則化CCAや事前にPCAで次元を落としてからCCAを行う設計が現実的である。

## 8. NMF：非負制約で混合を分解しやすい
非負データ X≥0 に対し
$$
X \approx W H,\quad W\ge 0,\ H\ge 0
$$
を満たす分解である。PCAは負の成分が許されるため「差分的」な基底になりやすいが、NMF は「足し合わせ」で説明しやすく、混相回折パターンや混合スペクトルの寄与分解に向くことが多い。

ただし解は一般に一意でなく、初期値依存・局所解の問題があるため、複数初期化やスパース化などの設計が重要である。

## 9. 注意点
1) 標準化の方針
記述子群では標準化が有効なことが多い。一方スペクトルでは正規化方法が物理解釈を変え得るため、目的（相分離か定量か）に応じて選ぶ。

2) 分割（validation）の設計
近縁組成・同一系列・同一ロットが train/test に跨ると、見かけ性能が上がりやすい。材料系では「系列分割」「組成領域での外挿評価」を意識する。

3) 成分数 r の決定
- PCA：寄与率（explained variance）、再構成誤差、下流タスク性能で決める
- PLS：交差検証で最適成分数を決める
- MDS：固有値の正負（距離がユークリッドでない場合）に注意する

4) 解釈の節度
線形手法は解釈しやすいが、「成分＝原因」ではない。負荷・寄与の可視化は仮説生成の材料とし、追加実験・追加計算で裏取りする設計が重要である。

## まとめ
線形次元削減は、材料データの高次元性と多重共線性を抑え、可視化・ノイズ低減・特徴抽出を同時に実現する基盤技術である。PCA/SVDを中心に、距離設計が鍵となるMDS、ラベルを活かすLDA/PLS、マルチモーダルを結ぶCCA、寄与分解に強いNMFを、データの生成過程（物理・測定）と評価設計（外挿・リーク対策）を先に置いて使い分けるのが実務上の要点である。

