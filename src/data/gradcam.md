# Grad-CAM（Gradient-weighted Class Activation Mapping）

Grad-CAMは、畳み込みニューラルネットワーク（CNN）が入力画像のどこを根拠に特定クラスを予測したかをヒートマップとして可視化する手法である。材料科学では、組織画像や破壊進展、欠陥検出などに用いることで、モデルが「どの組織特徴に依存して判断しているか」を解析する枠組みとして位置づけられる。

## 参考ドキュメント
- Selvaraju et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, ICCV 2017.
  https://openaccess.thecvf.com/content_ICCV_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html
- Oviedo et al., Interpretable and Explainable Machine Learning for Materials Science, Acc. Mater. Res. 2022.
  https://pubs.acs.org/doi/10.1021/accountsmr.1c00244
- Qiita: CAM/Grad-CAMによる画像認識モデルの信頼性向上
  https://qiita.com/sasshi_i/items/40716d6367b54230e46f


## 1. 位置づけと目的

Grad-CAMは、説明可能AI（Explainable AI, XAI）の一種であり、特定の入力とその予測に対する「局所的説明」を与える手法である。対象は主としてCNNベースの画像モデルであるが、1次元・時系列・セグメンテーションなどにも拡張されている。

材料科学の文脈では、以下の目的で利用されることが多い。
- 組織・欠陥画像に対するモデルの「視線」を可視化し、ドメイン知識と整合するかを検証する。
- モデルが見てはいけない領域（ラベルリーク、スケールバー、測定装置の特徴など）を利用していないかを確認する。
- 破壊起点・相境界・析出物など、従来の指標では捉えにくい特徴の重要性を探索する。

## 2. 基本アイデア

Grad-CAMは、次の2つの情報からクラスごとの重要度マップを構成する。
1. 最終畳み込み層の特徴マップ（チャネルごとの「どこに何があるか」）
2. 予測スコアに対する特徴マップの勾配（各チャネルがそのクラスにどれだけ寄与したか）

すなわち「どこで強く活性化しているか」と「どの活性がそのクラスに効いているか」を掛け合わせることで、「そのクラスの決定に効いている場所」を可視化するという考え方である。

## 3. 数式による定義

入力画像に対し、関心のあるクラスを $c$ とする。最終畳み込み層の $k$ 番目の特徴マップを $A^k\in\mathbb{R}^{H\times W}$、クラススコアを $y^c$ とする（ソフトマックス前のログitで扱うことが多い）。

1. 各チャネルの「クラス $c$ に対する重要度」係数
   $$
   \alpha_k^c=\frac{1}{Z}\sum_{i}\sum_{j}\frac{\partial y^c}{\partial A_{ij}^k}
   $$
   ここで $Z=H\times W$ は空間位置の総数であり、特徴マップ全体にわたる平均勾配で重みを定義している。

2. クラス $c$ に対するGrad-CAMマップ
   $$
   L_{\mathrm{Grad-CAM}}^c=\mathrm{ReLU}\left(\sum_k \alpha_k^c A^k\right)
   $$
   ReLUにより、クラススコアを増加させる方向の寄与のみを残すことで、「そのクラスを支持する領域」を強調する。

3. 得られた $L_{\mathrm{Grad-CAM}}^c$ を入力画像の解像度に補間し、元画像に重ね合わせることでヒートマップとして可視化する。

この枠組みにより、畳み込み層の構造に大きな制約を課さずに、多くのCNNアーキテクチャへ適用できる点が特徴である。

## 4. CAMとの違いと派生手法

### 4.1 Class Activation Mapping（CAM）との違い

CAMは、Global Average Pooling（GAP）と線形分類器を前提とした手法であり、「特徴マップとクラス重みの線形結合」によってアクティベーションマップを構成する。そのため、GAP層がないネットワークには直接適用しにくいという制約がある。

Grad-CAMは
- 勾配を使って「事実上のクラス重み」を推定するため、GAPや特定の構造に依存しない。
- 既存の多様なCNN（ResNet、DenseNet、U-Net系など）に後付けで適用しやすい。

材料の既存モデル（欠陥検出U-Net、組織分類ResNetなど）に対しても、構造を大きく変えずに可視化を導入できる点が実務上重要である。

### 4.2 派生手法

- Guided Grad-CAM
  - 入力勾配ベースの可視化（Guided Backpropagation）とGrad-CAMを組み合わせ、高解像度かつクラス判別的なヒートマップを得る手法である。
- Layer-wise Grad-CAM / Multilayer Grad-CAM
  - 複数の畳み込み層からGrad-CAMマップを得て統合することで、粗い高レベル特徴と細かい低レベル特徴の両方を反映したマップを得る手法である。
- 時系列・1D信号への拡張
  - 1D畳み込みモデルに対して同様の式を適用し、「どの時間区間・周波数帯がクラス決定に効いているか」を可視化する。

## 5. 材料科学における典型的な利用シナリオ

### 5.1 組織・欠陥画像の解析

- 光学顕微鏡像，SEM/TEM像
  - フェライト/パーライトの相割合分類、マルテンサイトの形態分類などで、モデルがどの相・粒界・析出物を見ているのかを確認する。
- EBSD・ECCI・位相コントラスト像
  - 転位セル構造やサブグレイン境界など、専門家が注目する特徴とGrad-CAMの高強度領域が一致しているかを検証し、モデルの妥当性を評価する。
- X線CTや放射光イメージング
  - 疲労き裂先端やボイド、微小欠陥の自動検出モデルに対し、き裂先端や塑性域など物理的に重要な領域にGrad-CAMが集中しているかを確認することで、信頼性向上に寄与する。

### 5.2 破壊・疲労メカニクスとGrad-CAM

- き裂先端のセマンティックセグメンテーション
  - CNN/UNetベースのモデルがき裂先端や損傷帯をどのように識別しているかをGrad-CAMで可視化し、誤検出の原因解析やデータセットの偏りの検出に役立てる。
- 亀裂進展経路の予測
  - 連続観察画像列に対して、き裂進展の予測モデルが「どの局所ひずみ集中や組織特徴」を手がかりにしているかを解析する。

### 5.3 スペクトル・時系列データへの拡張

1D CNNや時系列モデルにGrad-CAMを適用することで、以下のような用途が考えられる。
- XRD/XAFS/XPSスペクトル
  - どのピーク・肩・プリエッジ・ポストエッジ部分が相識別・状態識別に寄与しているかを可視化する。
- 磁気特性の時系列（B-H波形、MBN波形など）
  - 磁区反転イベントやノイズバーストのどの時間区間が分類・異常検知に効いているかをハイライトする。
- AE（アコースティックエミッション）・振動データ
  - 損傷進展やき裂発生のシグナルをCNNで検知する際に、どのパルスや周波数帯が決定に重要かを示す。

### 5.4 文献テキスト・マルチモーダルデータ

近年は、ResNetやCNNとテキストを組み合わせたモデルにGrad-CAMを適用し、
- 材料名・処理条件・性能値といったテキスト情報のうち、どの単語や句が分類・抽出に寄与したか
- 画像＋テキスト（図表説明文）のマルチモーダルモデルにおいて、どの図中領域とテキスト片が強く紐づいているか
といった解析も行われつつある。

## 6. ワークフロー

Grad-CAM算出のフローは概ね以下の通りである。

1. 対象モデルと、可視化したい中間層（通常は最終畳み込み層）を指定する。
2. 入力画像を与え、順伝播によりクラススコア $y^c$ を得る（対象クラス $c$ を指定）。
3. 逆伝播により、$y^c$ の中間特徴マップ $A^k$ に対する勾配 $\partial y^c / \partial A_{ij}^k$ を計算する。
4. 勾配を空間平均してチャネル重み $\alpha_k^c$ を求める。
5. $L_{\mathrm{Grad-CAM}}^c=\mathrm{ReLU}\big(\sum_k \alpha_k^c A^k\big)$ を計算する。
6. $L_{\mathrm{Grad-CAM}}^c$ を入力画像サイズに補間し、擬似カラーで重ね合わせる。

実装上は、自動微分ライブラリ（PyTorchやTensorFlowなど）の勾配計算機能を用いて、勾配と特徴マップをフックする形で行うことが多い。

## 7. 利点と限界

### 7.1 利点

- 多くのCNNアーキテクチャに適用可能であり、既存の材料画像モデルに「後付け」しやすい。
- 追加学習を必要とせず、推論＋1回の逆伝播でヒートマップが得られるため計算コストが比較的低い。
- 材料研究者が慣れ親しんだヒートマップ表現（例えば局所応力分布やエネルギー密度分布）に近く、直感的な解釈がしやすい。

### 7.2 注意点

- 解像度が特徴マップに依存するため、細かな組織（ナノ析出物など）を直接分離できない場合がある。
- 勾配に基づくため、勾配消失・飽和・数値不安定性の影響を受けることがある。
- Grad-CAMは「ネットワークがどこを使っているか」を示すだけであり、「そこが物理的に因果的な要因である」とまでは言えない。
- 不適切な学習データ（ラベルリーク、偏ったサンプル）を用いている場合、Grad-CAMはその偏りを可視化するだけであり、モデルの妥当性を保証するものではない。

材料科学で利用する際は、
- 物理モデルや実験知見との整合性の観点から「納得できるか」を確認する
- 入力の一部をマスク・除去しても予測が変わるかを確かめる（摂動テスト）
- 複数のXAI手法（Grad-CAM以外の特徴量重要度、サリエンシー、SHAPなど）を併用してクロスチェックする
ことが望ましい。

## 8. まとめ

Grad-CAMは、CNNベースのモデルが入力画像のどの領域を根拠として特定クラスを予測したかを、勾配と特徴マップに基づき可視化する手法である。材料科学においては、組織・欠陥・き裂・スペクトルなどの「どの特徴にモデルが依存しているか」を視覚的に把握し、モデルの妥当性評価・データセット設計・新たな仮説生成に活用できる枠組みである。

一方で、Grad-CAMはあくまで「モデル内部の重み付き視線」を可視化する手法であり、因果関係や物理法則を直接示すものではない。そのため、物理的知見・追加実験・他のXAI手法との併用を通じて、Grad-CAMで得られた示唆を慎重に解釈し、材料設計・機構解明に結び付けていくことが重要である。
 
