# リザバーコンピューティング（Reservoir Computing; RC）

リザバーコンピューティングは、時系列データを扱うためのリカレント型モデルであり、学習を出力層（readout）のみに限定することで、学習を高速・安定にする枠組みである。材料科学では、計測時系列（その場XRD/XAFS、磁気応答、プロセスログ）やシミュレーション時系列（MD軌跡、相変態ダイナミクス）を、軽量に予測・分類・異常検知する目的で有用である。

## 参考ドキュメント
- 田中剛平, リザバーコンピューティング, 映像情報メディア学会誌 74(3) (2020) 
  https://www.jstage.jst.go.jp/article/itej/74/3/74_532/_article/-char/ja/
- M. Lukoševičius and H. Jaeger, Reservoir Computing Approaches to Recurrent Neural Network Training, Computer Science Review (2009)（PDF）
  https://neuro.bstu.by/ai/To-dom/My_research/Papers-2.0/Echo-state-nn/2261_LukoseviciusJaeger09.pdf
- Z. Liu et al., Interface-type tunable oxygen ion dynamics for physical reservoir computing, Nature Communications (2023) 
  https://www.nature.com/articles/s41467-023-42993-x


## 1. 位置づけ：RNNの中でのRC
RCは、RNNの「中間状態（リザバー）」を原則固定し、観測したい量に対応する線形（または軽い非線形）読み出しだけを学習する。

代表的な2系統
- Echo State Network（ESN）：連続値の状態ベクトルを持つ、工学系で広く使われるRC
- Liquid State Machine（LSM）：スパイキング等の「液体（liquid）」的ダイナミクスを利用するRC

## 2. 基本モデル（ESN）の数式
記号
- 入力：$u(t) \in \mathbb{R}^{d_u}$
- リザバー状態：$x(t) \in \mathbb{R}^{d_x}$
- 出力：$y(t) \in \mathbb{R}^{d_y}$

状態更新（例：tanh）
$$
x(t+1) = (1-\alpha)x(t) + \alpha \tanh\left(W_{\mathrm{in}} u(t+1) + W x(t) + b\right)
$$

読み出し（線形）
$$
y(t) = W_{\mathrm{out}} \begin{bmatrix} x(t) \\ u(t) \\ 1 \end{bmatrix}
$$

ここで $\alpha$ はリーク率（leaky integration）。$W_{\mathrm{in}}, W, b$ は固定（または軽微な調整のみ）で、学習するのは通常 $W_{\mathrm{out}}$ のみ。

## 3. 学習：読み出しだけを回帰で求める
教師信号を $y^{\ast}(t)$ とし、状態を時間方向に積んで
- 状態行列：$X = [\tilde{x}(t_1), \tilde{x}(t_2), ...]$（$\tilde{x}=[x;u;1]$）
- 目標行列：$Y^{\ast} = [y^{\ast}(t_1), y^{\ast}(t_2), ...]$

リッジ回帰（標準的）
$$
W_{\mathrm{out}} = Y^{\ast} X^{\top}\left(XX^{\top} + \beta I\right)^{-1}
$$
- $\beta$：正則化（ノイズや過学習への耐性を上げる）

運用上の定番テクニック
- washout：初期状態依存を捨てるため、序盤の数十〜数百ステップは学習に使わない
- 正規化：入力スケーリング（平均0、分散1、または物理量として意味のあるレンジに）
- 検証：時系列はシャッフルせず、ブロック分割やウォークフォワード検証を基本にする

## 4. RCが効く理由
- リザバーが入力履歴を「高次元の状態」として保持する（短期記憶）
- 非線形写像で特徴を増やす（カーネル的な効果）
- 読み出しが線形でも、リザバーが非線形なら十分表現できる場合が多い
- 学習が線形回帰なので、学習が速く、データが少なめでも破綻しにくい

## 5. 重要ハイパーパラメータ（材料時系列で効きやすい順）
- リザバー次元 $d_x$：大きいほど表現力は増えるが、過学習・計算量も増える
- スペクトル半径（spectral radius）$\rho(W)$：記憶の長さ・安定性に関与（大きすぎると不安定になりやすい）
- 入力スケール：非線形領域に入れる強さ（小さすぎると線形すぎ、大きすぎると飽和）
- リーク率 $\alpha$：時間スケールを合わせる（遅い現象には小さめが効くことが多い）
- 正則化 $\beta$：ノイズの多い実験時系列では強めが効くことが多い

## 6. 材料科学での典型ユースケース
### 6.1 計測データ（実験）に強い
- その場測定のスペクトル時系列（XRD/XAFS/XMCDなど）の
  - 短期予測（次の数ステップ）
  - 状態推定（潜在状態の代替として $x(t)$ を使う）
  - 相転移・反応開始の兆候検出（異常検知）
- 磁気応答の時系列（例：B-Hループの時間発展、MBN波形列、VNA透過の周波数掃引時系列）
  - パターン識別（処理条件・欠陥状態の分類）
  - 劣化・異常の早期検出

ポイント
- 深層学習より軽いので、実験の少量データでも試しやすい
- ノイズに対しては、正則化＋入力/出力の前処理が効く

### 6.2 シミュレーション（計算）を軽量 surrogate にする
- MDのある物理量（エネルギー、応力、配位数など）の時系列予測
- 相変態・反応のマクロ変数の時系列の高速近似
- フェーズフィールドやマルチフィジックスの“時間発展だけ”を近似する軽量モデル（制御や逆解析の前段として）

注意
- 空間場そのもの（画像・3D格子）を出したい場合は、RC単体よりも
  - RCで低次元状態を推定 → 別のデコーダで場へ復元
  - あるいは画像系（U-Net等）と組み合わせる
が扱いやすい。

## 7. 物理リザバー（physical RC）と材料の接点
RCは「リザバー＝力学系」を物理現象で置き換えられる。

例
- 光回路（フォトニクス）によるRC：高速・低消費電力を狙う
- メモリスタ・イオン移動・強誘電・界面現象：非線形と履歴（メモリ）をデバイス物性で実装
- ランダムネットワーク材料（ナノワイヤネットワーク等）：in-materio（材料そのものが計算資源）

材料屋としての設計観点
- 非線形性：入力の差が状態差として広がるか
- fading memory：過去は残るが、無限に残り続けない（安定）
- 再現性：同条件で同じ応答が出るか（実験では重要）
- ノイズ耐性：温度・劣化・ドリフトに対して性能が落ちにくいか
- 入出力インタフェース：どう信号を入れて、どう読み出すか（測定容易性）

## 8. 導入手順
1. タスク定義：予測か、分類か、異常検知か（出力 $y(t)$ を決める）
2. データ整形：サンプリング間隔を揃える、外れ値処理、正規化
3. ESN構築：$d_x$, $\rho(W)$, 入力スケール, $\alpha$, washout を決める
4. 読み出し学習：リッジ回帰で $W_{\mathrm{out}}$ を学習（検証は時系列分割）
5. 解釈：読み出し重みと状態 $x(t)$ の寄与を調べ、物理量（温度・組成・欠陥など）との相関を見る

## 9. よくある落とし穴
- 未来情報リーク：前処理で全データの平均・分散を使ってしまう（学習区間だけで算出）
- シャッフルCV：時系列でランダム分割すると過大評価になりやすい
- スケール不整合：入力が大きすぎてtanhが飽和し、情報が潰れる
- washout不足：初期条件依存が残って性能が揺れる
- 物理解釈なし：当たるだけで止めず、状態と材料因子の対応づけを行う

## まとめ
リザバーコンピューティングは、学習を読み出しに限定することで、時系列解析を高速・軽量に実現する枠組みであり、材料計測やシミュレーションの時系列に特に相性が良い。さらに物理リザバーの方向では、材料・デバイス物性そのものを計算資源として設計できるため、材料科学の強み（物性設計・計測・プロセス）と直結したAI4Scienceの題材になり得る。