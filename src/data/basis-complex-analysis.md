# 機械学習のための複素解析入門

複素解析は、複素数を変数とする関数の微分・積分を扱う理論であり、周波数解析・波動表現・確率特性関数・複素パラメータ最適化などを通じて機械学習にも繰り返し現れる枠組みである。特に、正則性（複素微分可能性）とウィルティンガー微分（非正則でも扱える複素偏微分）を区別して理解すると、数式の意味と実装上の挙動が一致しやすくなるのである。

### 参考ドキュメント
- 田橋範宏, 複素関数論 講義ノート（PDF）
  https://www2.yukawa.kyoto-u.ac.jp/~norihiro.tanahashi/pdf/complex-analysis/note.pdf
- Kreutz-Delgado, The Complex Gradient Operator and the CR-Calculus（PDF）
  https://arxiv.org/pdf/0906.4835
- 林和則, 初学者のための無線通信信号処理入門（ウィルティンガー微分の説明を含むPDF）
  https://kazunorihayashi.github.io/paper/rcs201707.pdf
  
## 1. 複素数と複素平面

複素数は
$$
z=x+iy \quad (x,y\in\mathbb{R},\ i^{2}=-1)
$$
と表す。実部と虚部は
$$
\mathrm{Re}\,z=x,\quad \mathrm{Im}\,z=y
$$
であり、共役複素数は
$$
\bar{z}=x-iy
$$
である。大きさ（絶対値）と偏角（位相）は
$$
|z|=\sqrt{x^{2}+y^{2}},\quad z=|z|e^{i\theta}
$$
で与えられる（$\theta=\arg z$）。この極形式の意味は、複素数を平面上のベクトルと見たときの「伸縮（|z|）」と「回転（\theta）」に対応する点にある。

オイラーの公式
$$
e^{i\theta}=\cos\theta+i\sin\theta
$$
により、複素指数は三角関数を統一的に扱う道具となる。機械学習では、フーリエ変換やスペクトル領域の特徴量、回転不変量（位相差）の表現でこの構造が頻繁に現れる。

## 2. 複素関数と極限

複素関数は $f:\mathbb{C}\to\mathbb{C}$ と書き、
$$
f(z)=u(x,y)+iv(x,y)
$$
（$u,v:\mathbb{R}^{2}\to\mathbb{R}$）と実2変数関数として同一視できる。

極限
$$
\lim_{z\to z_{0}} f(z)=w
$$
は、平面上のどの方向から $z\to z_{0}$ と近づけても同じ値 $w$ に近づくことを意味する。実1変数と比べて「近づき方」が無数にあるため、後述する複素微分可能性は非常に強い制約になるのである。

## 3. 複素微分と正則性：コーシー・リーマン方程式の意味

### 3.1 複素微分（複素導関数）の定義

複素微分は
$$
f'(z_{0})=\lim_{h\to 0}\frac{f(z_{0}+h)-f(z_{0})}{h}
$$
で定義する。ここで $h\in\mathbb{C}$ である点が決定的であり、$h$ の近づけ方（方向）が変わっても極限が一致するときにのみ微分可能である。

この条件を $f(z)=u(x,y)+iv(x,y)$ で書き下すと、必要条件としてコーシー・リーマン方程式
$$
\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y},\quad
\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}
$$
が得られる。さらに $u,v$ が十分滑らかならこれは十分条件にもなる。

コーシー・リーマン方程式の意味は、実2変数の自由度の一部が縛られて「2次元なのに1次元のような（強い）構造」が生まれる点にある。正則関数が強力なのは、この構造から積分定理や級数展開が連鎖的に導かれるからである。

### 3.2 正則と解析的

開集合上で複素微分可能である関数を正則関数と呼ぶ。正則関数は局所的にべき級数展開できる（テイラー展開）という意味で解析的（analytic）である、という結論に到達する（関数論の大きな特徴である）。

機械学習では「解析的であること」自体より、正則性（holomorphic）がもたらす性質（滑らかさ、等角性、強い一意性、積分公式）を計算や表現に利用する場面が多い。

## 4. 正則関数の幾何：等角写像と調和関数

正則関数 $f(z)=u+iv$ の実部・虚部はラプラス方程式
$$
\nabla^{2}u=\frac{\partial^{2}u}{\partial x^{2}}+\frac{\partial^{2}u}{\partial y^{2}}=0,\quad
\nabla^{2}v=0
$$
を満たす（$u,v$ は調和関数である）。これはコーシー・リーマン方程式を2階微分して得られる。

また、$f'(z_{0})\neq 0$ なら局所的に角度を保つ（等角写像）性質を持つ。これはデータを複素平面に埋め込み、局所形状を歪めにくい変換として解釈できるが、機械学習で直接用いる場合は「局所構造保存」という語感だけでなく、正則性が強すぎて表現力を制限する点も同時に意識する必要がある。

## 5. 複素積分：線積分としての意味

複素積分は曲線 $\gamma$ 上で
$$
\int_{\gamma} f(z)\,dz
$$
と書く。パラメータ表示 $z=z(t)$（$t\in[a,b]$）で
$$
\int_{\gamma} f(z)\,dz=\int_{a}^{b} f(z(t))\,z'(t)\,dt
$$
である。

この式の意味は、複素積分が「2次元平面の曲線に沿った線積分」であり、実積分の一般化である点にある。以後の定理は、この線積分が正則性により劇的に簡単になることを主張する。

## 6. コーシーの定理と積分公式：局所情報が大域を決める

### 6.1 コーシーの積分定理

単連結領域で $f$ が正則なら、閉曲線 $C$ に沿って
$$
\oint_{C} f(z)\,dz = 0
$$
が成り立つ。直観としては、正則性が「渦なし」のような構造を作り、循環積分が消えると理解できる。

### 6.2 コーシーの積分公式

$C$ を $z_{0}$ を囲む単純閉曲線とし、内部で $f$ が正則なら
$$
f(z_{0})=\frac{1}{2\pi i}\oint_{C}\frac{f(z)}{z-z_{0}}\,dz
$$
が成り立つ。これは、曲線上の値から内部の値が復元できるという強い主張である。

さらに微分も
$$
f^{(n)}(z_{0})=\frac{n!}{2\pi i}\oint_{C}\frac{f(z)}{(z-z_{0})^{n+1}}\,dz
$$
で与えられる。すなわち、正則関数は滑らかさというより「内部が境界に支配される」という特殊な性質を持つのである。

機械学習への連想としては、カーネル法や調和拡張、正則化での境界条件の重要性が挙げられるが、ここでの結論は「正則性はそれほど強い」という点に尽きる。

## 7. べき級数・ローラン級数：特異点の分類

### 7.1 テイラー展開（正則点）

$f$ が $z_{0}$ の近傍で正則なら
$$
f(z)=\sum_{n=0}^{\infty} a_{n}(z-z_{0})^{n},\quad
a_{n}=\frac{f^{(n)}(z_{0})}{n!}
$$
である。ここでは「収束半径内で関数が完全に決まる」点が重要である。

### 7.2 ローラン展開（孤立特異点を含む）

孤立特異点を含む環状領域では
$$
f(z)=\sum_{n=-\infty}^{\infty} a_{n}(z-z_{0})^{n}
$$
と展開できる。負の次数部分（主要部）が特異性を記述する。

特異点は主要部の形で分類できる。

- 可除特異点：主要部がない（$a_{-1}=a_{-2}=\cdots=0$）
- 極：主要部が有限個（ある $m$ で $a_{-m}\neq 0$、それより小さい次数は0）
- 真性特異点：主要部が無限に続く

この分類は、次の留数定理に直結する。

## 8. 留数定理：積分が代数計算に落ちる

### 8.1 留数の定義

ローラン展開
$$
f(z)=\cdots + \frac{a_{-1}}{z-z_{0}} + a_{0} + a_{1}(z-z_{0})+\cdots
$$
の係数 $a_{-1}$ を留数と呼び、
$$
\mathrm{Res}(f,z_{0})=a_{-1}
$$
と書く。

### 8.2 留数定理

閉曲線 $C$ の内部にある孤立特異点を $\{z_{k}\}$ とすると
$$
\oint_{C} f(z)\,dz = 2\pi i \sum_{k}\mathrm{Res}(f,z_{k})
$$
が成り立つ。

留数定理の意味は、複素積分が「内部特異点の局所情報の和」に還元される点にある。これにより、実積分や逆ラプラス変換などの計算が整理される。

### 8.3 機械学習との接点：スペクトル・確率・漸近

留数や複素積分は、次のような局面で現れる。

- フーリエ解析：複素指数 $e^{i\omega t}$ によるスペクトル表現
- 特性関数：確率分布のフーリエ変換（複素指数を含む）
- 漸近解析：鞍点法・最急降下法（複素平面上の経路変形）
- 逆変換：ラプラス逆変換や生成関数の係数抽出

深層学習の学習則そのものよりも、信号処理・確率・統計物理寄りの理論整理で顔を出すことが多い。

## 9. 枝（branch）と多価関数：対数・べき乗の注意点

複素対数は多価である。
$$
\log z = \ln|z| + i(\arg z + 2\pi k),\quad k\in\mathbb{Z}
$$
したがって、$\arg z$ の取り方（主値）を決め、枝切り線（branch cut）により単価化する必要がある。

機械学習では、複素スペクトルの位相を扱うとき（位相復元や複素パラメータ最適化）に、位相の不連続（$-\pi$ と $\pi$ が同一視される）を意識する必要がある。ここでの本質は「表現が数学的に多価である」点である。

## 10. 複素解析と最適化：正則微分とウィルティンガー微分（CR-calculus）

機械学習で重要なのは、最適化対象の損失がほとんど常に実数値だという点である。複素パラメータ $z$ を用いて損失 $L$ を書くと、多くの場合
$$
L=L(z,\bar{z})\in\mathbb{R}
$$
となり、$L$ は一般に正則ではない（$\bar{z}$ にも依存する）ので、通常の複素微分 $dL/dz$ をそのまま使うと破綻する。ここでウィルティンガー微分が有効になる。

### 10.1 ウィルティンガー微分の定義（$z$ と $\bar{z}$ を独立扱いする）

$z=x+iy$ として、次を定義する。
$$
\frac{\partial}{\partial z}
=\frac{1}{2}\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}\right),\quad
\frac{\partial}{\partial \bar{z}}
=\frac{1}{2}\left(\frac{\partial}{\partial x}+i\frac{\partial}{\partial y}\right)
$$

このとき $f(z)$ が正則であることは
$$
\frac{\partial f}{\partial \bar{z}}=0
$$
と同値になる。つまり「正則性の判定器」としても理解できる。

### 10.2 共役ウィルティンガー勾配（実数値損失の降下方向）

実数値 $L(z,\bar{z})$ のとき、最急降下方向は
$$
-\frac{\partial L}{\partial \bar{z}}
$$
と表される（定義流儀によって定数倍は変わりうるが、$\partial/\partial \bar{z}$ 側が降下に自然に出る点が重要である）。

最も基本的な例として
$$
L(z)=|z|^{2}=z\bar{z}
$$
なら
$$
\frac{\partial L}{\partial z}=\bar{z},\quad
\frac{\partial L}{\partial \bar{z}}=z
$$
となり、降下は $z\leftarrow z-\eta z$ であり、原点へ縮む挙動と一致する。

### 10.3 自動微分での扱い

多くの自動微分ライブラリは、複素を実2次元として扱う規約を持ち、実数値損失に対して「降下に整合する勾配」を返す設計になっている。ここで返る勾配が何に対応するか（$\partial/\partial z$ か $\partial/\partial \bar{z}$ か、共役が付くか）は規約で決まるため、理論式と照合して理解することが重要である。

## 11. 複素値ニューラルネットワーク（CVNN）：複素解析が現れる場所

複素値ニューラルネットワークでは、重み・活性・出力が複素となる。複素表現が自然に現れるデータとして、IQ信号、レーダ・通信、スペクトログラム（複素STFT）、回転や位相を含む表現などが挙げられる。

### 11.1 活性化関数と正則性

複素活性化を正則にしようとすると、関数形は強く制限される。例えば、複素平面全体で正則かつ有界なら定数である（リウヴィルの定理）。したがって、実用上は非正則な活性化（実部と虚部に別々に作用させる、振幅と位相に分ける等）を採用し、学習則はウィルティンガー微分やCR-calculusで記述することが多い。

### 11.2 表現の利点の言い換え

複素は「2次元を1つの数で持てる」だけでなく、回転が積で書けるため、位相や回転に関する構造を式変形で保ちやすい。これは、座標系の取り方に依存しにくい表現を作りやすいことを意味する。

## 12. まとめ表

| 話題 | 中心概念 | 数式の核 | 機械学習側の接点 |
|---|---|---|---|
| 複素数 | 回転と伸縮 | $z=ze^{i\theta}$ | フーリエ特徴、位相、回転表現 |
| 正則性 | 強い微分可能性 | CR方程式 | 等角性、調和関数、滑らかな写像 |
| コーシー積分公式 | 境界が内部を決める | $f(z_{0})=\frac{1}{2\pi i}\oint\frac{f(z)}{z-z_{0}}dz$ | 境界条件、再構成、解析接続の直観 |
| 留数定理 | 大域積分の代数化 | $\oint fdz=2\pi i\sum \mathrm{Res}$ | 逆変換、漸近、特性関数 |
| ウィルティンガー微分 | 非正則の微分 | $\partial/\partial z,\partial/\partial \bar{z}$ | 複素パラメータ最適化、複素オートグラド |
| CVNN | 複素表現学習 | $L(z,\bar{z})$ | 通信・信号、複素スペクトル |

## 13. ウィルティンガー微分の例

次の例は、$L(z)=|z|^{2}$ の降下が $z\leftarrow (1-\eta)z$ になることを数値で確認する一例である。複素最適化の直観（原点に向けて縮む）を固定する目的がある。

```python
import numpy as np

def loss(z):
    return (z * np.conjugate(z)).real  # |z|^2 を実数として返す

# 解析的には ∂L/∂\bar{z} = z なので、降下は z <- z - eta * z
z = 1.0 + 2.0j
eta = 0.2

for t in range(5):
    print(t, z, loss(z))
    z = z - eta * z  # 最急降下（規約により定数倍はありうるが、方向はこれで一致する）
```

この更新で $|z|$ が指数的に減少することが確認できる。より一般の $L(z,\bar{z})$ でも、降下方向が $\partial/\partial \bar{z}$ 側に現れる、という構造が基本である。


## まとめと展望
複素解析の核心は、正則性がもたらす強い構造（コーシーの定理・積分公式・級数展開）と、特異点を軸にした計算体系（ローラン展開と留数定理）にある。機械学習では、複素指数による周波数表現や確率の特性関数だけでなく、複素パラメータの学習則を整理するために、正則微分とウィルティンガー微分を区別して理解することが効くのである。

今後の展望として、(1) 複素オートグラドの規約が何を返しているかを数式と突き合わせて整理すること、(2) 複素値表現が自然なデータ領域（通信・音響・レーダ・スペクトル）でCVNNの設計自由度を理論に沿って増やすこと、(3) 留数・鞍点法などの複素解析的手法を、分布の正規化や漸近評価の理解に結び付けること、が有望である。これらを通じ、複素解析は「計算できる理論」と「学習可能な表現」を繋ぐ基礎語彙として機械学習の理解を支え続けるのである。

## 参考文献
- Brandwood, A complex gradient operator and its application in adaptive array theory（IET, PDF）
https://digital-library.theiet.org/doi/pdf/10.1049/ip-f-1.1983.0003?download=true

- Bassey et al., A Survey of Complex-Valued Neural Networks（arXiv）
https://arxiv.org/abs/2101.12249

- Lee et al., Complex-Valued Neural Networks: A Comprehensive Survey（IEEE JAS）
https://www.ieee-jas.net/article/doi/10.1109/JAS.2022.105743

- NOLTA（J-STAGE）, Proposal of fully augmented complex-valued neural networks
https://www.jstage.jst.go.jp/article/nolta/14/2/14_175/_article

- JAX Documentation, Autodiff cookbook（複素数と微分の節を含む）
https://docs.jax.dev/en/latest/notebooks/autodiff_cookbook.html

- PyTorch Documentation, Complex Numbers（Autogradの節に複素勾配の説明を含む）
https://docs.pytorch.org/docs/stable/complex_numbers.html

- 名古屋大学, 現代数学基礎CIII 講義ノート（複素解析の参考文献情報を含むPDF）
https://www.math.nagoya-u.ac.jp/~yanagida/edu/23W/2023CIII.pdf

- 兵庫県立大学, 応用解析：講義ノート（留数定理の実積分への応用を含むPDF）
https://www.sci.u-hyogo.ac.jp/material/theory1/sakai/ca.pdf

- 北海道大学, 複素解析（PDF）
https://www.ep.sci.hokudai.ac.jp/~keikei/lecture/math-note.pdf

